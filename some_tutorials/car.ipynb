{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to any reinforcemnet learning there are three main questions that we need to answer:\n",
    "1. what is an state: The state is defined as pair of (number of cars remained in first location, number of cars remained in second location). Clearly the state space is (0,0) to (20,20)\n",
    "2. action space. Action is defined as number of cars transfer from location 1 to location 2. Action space is an integer number between -5 to 5. Negative number is reverse flow from location 2 to location 1.\n",
    "3. Environment: Given a space and an action, environment defines reward and next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class State(object):\n",
    "    def __init__(self, n1, n2):\n",
    "        self.n1 = min(max(n1, 0), 20)\n",
    "        self.n2 = min(max(n1, 0), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def env(state, action):\n",
    "    \"\"\"\n",
    "    @return: 1. reward for taking the action. Reward is a non-negative number\n",
    "             2. next state.\n",
    "    \"\"\"\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
