{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-18 17:48:37,930] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.02\n",
    "decay_rate = 0.99\n",
    "gamma = 0.99\n",
    "D  = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mH = 256\n",
    "\n",
    "previous_state = tf.placeholder(shape=[None, 5], name='previous_state', dtype=tf.float32)\n",
    "W1M = tf.get_variable(name='W1M', shape=[5, mH], initializer=tf.contrib.layers.xavier_initializer())\n",
    "B1M = tf.Variable(name='B1M', initial_value=np.zeros([mH]), dtype=tf.float32)\n",
    "layer1M = tf.nn.relu(tf.matmul(previous_state, W1M)+B1M, name='model_layer1')\n",
    "\n",
    "\n",
    "W2M = tf.get_variable(name='W2M', shape=[mH, mH], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "B2M = tf.Variable(name='B2M', initial_value=np.zeros([mH]), dtype=tf.float32)\n",
    "layer2M = tf.nn.relu(tf.matmul(layer1M, W2M)+B2M, name='model_layer2')\n",
    "\n",
    "WO = tf.get_variable(name='WO', shape=[mH,4], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "BO = tf.Variable(name='BO', initial_value=np.zeros([4], dtype=np.float32), dtype=tf.float32)\n",
    "\n",
    "WR = tf.get_variable(name='WR', shape=[mH,1], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "BR = tf.Variable(name='BR', initial_value=np.zeros([4], dtype=np.float32), dtype=tf.float32)\n",
    "\n",
    "WD = tf.get_variable(name='WD', shape=[mH,1], initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n",
    "BD = tf.Variable(name='BD', initial_value=np.zeros([4], dtype=np.float32), dtype=tf.float32)\n",
    "\n",
    "predicted_observation = tf.matmul(layer2M, WO) + BO\n",
    "predicted_reward = tf.matmul(layer2M, WR) + BR\n",
    "predicted_done = tf.matmul(layer2M, WD) + BD\n",
    "\n",
    "actual_observation = tf.placeholder(shape=[4], name='actual_observation', dtype=tf.float32)\n",
    "actual_reward = tf.placeholder(shape=[1], name='actual_reward', dtype=tf.float32)\n",
    "actual_done = tf.placeholder(shape=[1], name='actual_done', dtype=tf.float32)\n",
    "\n",
    "\n",
    "loss_sum = tf.squared_difference(predicted_observation, actual_observation) + \\\n",
    "tf.squared_difference(predicted_reward, actual_reward) + \\\n",
    "tf.squared_difference(predicted_done, actual_done)\n",
    "\n",
    "loss = tf.reduce_mean(loss_sum)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "update = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### policy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pH = 8\n",
    "prev_state = tf.placeholder(name='previous_state', shape=[None, 4])\n",
    "\n",
    "W1 = tf.get_variable(name='W1', shape=[4, pH], initializer=tf.contrib.layers.xavier_initializer())\n",
    "B1 = tf.Variable(name='B1', initializer=np.zeros([pH]))\n",
    "layer1 = tf.matmul(prev_state, W1) + B1\n",
    "\n",
    "W2 = tf.get_variable(name='W2', shape=[4, pH], initializer=tf.contrib.layers.xavier_initializer())\n",
    "B2 = tf.Variable(name='B2', initializer=np.zeros([pH]))\n",
    "layer2 = tf.matmul(layer1, W2) + B2\n",
    "\n",
    "W = tf.get_variable(name='W', shape=[pH, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "B = tf.Variable(name='B', initializer=np.zeros([1]))\n",
    "\n",
    "predicted_action = tf.nn.sigmoid(tf.matmul(layer2, W2) + B2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resetGradBuffer(gradBuffer):\n",
    "    for ix,grad in enumerate(gradBuffer):\n",
    "        gradBuffer[ix] = grad * 0\n",
    "    return gradBuffer\n",
    "        \n",
    "def discount_rewards(r):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    for t in reversed(xrange(0, r.size)):\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r\n",
    "\n",
    "\n",
    "# This function uses our model to produce a new state when given a previous state and action\n",
    "def stepModel(sess, xs, action):\n",
    "    toFeed = np.reshape(np.hstack([xs[-1][0],np.array(action)]),[1,5])\n",
    "    myPredict = sess.run([predicted_state],feed_dict={previous_state: toFeed})\n",
    "    reward = myPredict[0][:,4]\n",
    "    observation = myPredict[0][:,0:4]\n",
    "    observation[:,0] = np.clip(observation[:,0],-2.4,2.4)\n",
    "    observation[:,2] = np.clip(observation[:,2],-0.4,0.4)\n",
    "    doneP = np.clip(myPredict[0][:,5],0,1)\n",
    "    if doneP > 0.1 or len(xs)>= 300:\n",
    "        done = True\n",
    "    else:\n",
    "        done = False\n",
    "    return observation, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-7-0dc967ac30d5>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-0dc967ac30d5>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    rendering = False\n",
    "    s = env.reset()\n",
    "    for i in range(num_episodes):\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
